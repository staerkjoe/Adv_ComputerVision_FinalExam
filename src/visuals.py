import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from pathlib import Path
import wandb


class Visuals:
    def __init__(self, config, model):
        self.config = config
        self.model = model

    def count_parameters(self):
        """Count total and trainable parameters in the model."""
        if self.model is None:
            raise ValueError("Model not loaded. Call load_model() first.")
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        return total_params, trainable_params

    def plot_trainable_parameters(self, total_params, trainable_params):
        """Plot comparison of total vs trainable parameters."""
        if isinstance(total_params, dict):
            models = list(total_params.keys())
            totals = np.array([total_params[m] for m in models], dtype=float)
            if isinstance(trainable_params, dict):
                trains = np.array([trainable_params.get(m, 0) for m in models], dtype=float)
            else:
                trains = np.array(trainable_params, dtype=float)
        else:
            totals = np.atleast_1d(np.array(total_params, dtype=float))
            trains = np.atleast_1d(np.array(trainable_params, dtype=float))
            models = [str(i) for i in range(len(totals))]

        scale = 1e6
        totals_M = totals / scale
        trains_M = trains / scale

        fig, ax = plt.subplots(figsize=(10, 6))
        x = np.arange(len(models))
        width = 0.36

        bars_total = ax.bar(x - width/2, totals_M, width, label='Total params', color='#3498db')
        bars_train = ax.bar(x + width/2, trains_M, width, label='Trainable params', color='#2ecc71')

        ax.set_xticks(x)
        ax.set_xticklabels(models, rotation=30, ha='right')
        ax.set_ylabel('Parameters (M)', fontsize=12)
        ax.set_title('Model Complexity Comparison', fontsize=14, fontweight='bold')
        ax.legend()

        def annotate(bars, vals):
            max_h = max(np.max(totals_M) if len(totals_M) > 0 else 0, 
                       np.max(trains_M) if len(trains_M) > 0 else 0)
            offset = max_h * 0.02 if max_h > 0 else 0.01
            for bar, val in zip(bars, vals):
                ax.text(bar.get_x() + bar.get_width()/2,
                       bar.get_height() + offset,
                       f'{val:.2f}M',
                       ha='center', va='bottom', fontsize=9)

        annotate(bars_total, totals_M)
        annotate(bars_train, trains_M)

        plt.tight_layout()
        plt.close(fig)
        return fig

    def plot_training_losses(self, results_csv_path):
        """
        Plot train vs validation losses (box, cls, dfl) from Ultralytics results.
        
        Args:
            results_csv_path: Path to the results.csv file generated by Ultralytics
        """
        # Read the CSV file
        results_csv_path = Path(results_csv_path)
        if not results_csv_path.exists():
            print(f"Results CSV not found at {results_csv_path}")
            return None
        
        df = pd.read_csv(results_csv_path)
        df.columns = df.columns.str.strip()  # Remove whitespace from column names
        
        # Create figure with subplots for different loss components
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Training vs Validation Losses', fontsize=16, fontweight='bold')
        
        epochs = df['epoch'] if 'epoch' in df.columns else range(len(df))
        
        # Plot 1: Box Loss
        ax1 = axes[0, 0]
        if 'train/box_loss' in df.columns and 'val/box_loss' in df.columns:
            ax1.plot(epochs, df['train/box_loss'], label='Train Box Loss', 
                    color='#e74c3c', linewidth=2, marker='o', markersize=4)
            ax1.plot(epochs, df['val/box_loss'], label='Val Box Loss', 
                    color='#3498db', linewidth=2, marker='s', markersize=4)
            ax1.set_xlabel('Epoch', fontsize=11)
            ax1.set_ylabel('Box Loss', fontsize=11)
            ax1.set_title('Bounding Box Loss', fontsize=12, fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
        
        # Plot 2: Class Loss
        ax2 = axes[0, 1]
        if 'train/cls_loss' in df.columns and 'val/cls_loss' in df.columns:
            ax2.plot(epochs, df['train/cls_loss'], label='Train Class Loss', 
                    color='#e74c3c', linewidth=2, marker='o', markersize=4)
            ax2.plot(epochs, df['val/cls_loss'], label='Val Class Loss', 
                    color='#3498db', linewidth=2, marker='s', markersize=4)
            ax2.set_xlabel('Epoch', fontsize=11)
            ax2.set_ylabel('Class Loss', fontsize=11)
            ax2.set_title('Classification Loss', fontsize=12, fontweight='bold')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        
        # Plot 3: DFL Loss
        ax3 = axes[1, 0]
        if 'train/dfl_loss' in df.columns and 'val/dfl_loss' in df.columns:
            ax3.plot(epochs, df['train/dfl_loss'], label='Train DFL Loss', 
                    color='#e74c3c', linewidth=2, marker='o', markersize=4)
            ax3.plot(epochs, df['val/dfl_loss'], label='Val DFL Loss', 
                    color='#3498db', linewidth=2, marker='s', markersize=4)
            ax3.set_xlabel('Epoch', fontsize=11)
            ax3.set_ylabel('DFL Loss', fontsize=11)
            ax3.set_title('Distribution Focal Loss', fontsize=12, fontweight='bold')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # Plot 4: Combined Total Loss
        ax4 = axes[1, 1]
        # Calculate total loss (sum of all components)
        train_total = np.zeros(len(df))
        val_total = np.zeros(len(df))
        
        if 'train/box_loss' in df.columns:
            train_total += df['train/box_loss'].fillna(0)
        if 'train/cls_loss' in df.columns:
            train_total += df['train/cls_loss'].fillna(0)
        if 'train/dfl_loss' in df.columns:
            train_total += df['train/dfl_loss'].fillna(0)
            
        if 'val/box_loss' in df.columns:
            val_total += df['val/box_loss'].fillna(0)
        if 'val/cls_loss' in df.columns:
            val_total += df['val/cls_loss'].fillna(0)
        if 'val/dfl_loss' in df.columns:
            val_total += df['val/dfl_loss'].fillna(0)
        
        ax4.plot(epochs, train_total, label='Train Total Loss', 
                color='#e74c3c', linewidth=2, marker='o', markersize=4)
        ax4.plot(epochs, val_total, label='Val Total Loss', 
                color='#3498db', linewidth=2, marker='s', markersize=4)
        ax4.set_xlabel('Epoch', fontsize=11)
        ax4.set_ylabel('Total Loss', fontsize=11)
        ax4.set_title('Combined Loss', fontsize=12, fontweight='bold')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.close(fig)
        return fig

    def plot_metrics(self, results_csv_path):
        """
        Plot mAP metrics and precision/recall from Ultralytics results.
        
        Args:
            results_csv_path: Path to the results.csv file generated by Ultralytics
        """
        results_csv_path = Path(results_csv_path)
        if not results_csv_path.exists():
            print(f"Results CSV not found at {results_csv_path}")
            return None
        
        df = pd.read_csv(results_csv_path)
        df.columns = df.columns.str.strip()
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        fig.suptitle('Validation Metrics', fontsize=16, fontweight='bold')
        
        epochs = df['epoch'] if 'epoch' in df.columns else range(len(df))
        
        # Plot 1: Precision and Recall
        ax1 = axes[0]
        if 'metrics/precision(B)' in df.columns:
            ax1.plot(epochs, df['metrics/precision(B)'], label='Precision', 
                    color='#2ecc71', linewidth=2, marker='o', markersize=4)
        if 'metrics/recall(B)' in df.columns:
            ax1.plot(epochs, df['metrics/recall(B)'], label='Recall', 
                    color='#9b59b6', linewidth=2, marker='s', markersize=4)
        ax1.set_xlabel('Epoch', fontsize=11)
        ax1.set_ylabel('Score', fontsize=11)
        ax1.set_title('Precision & Recall', fontsize=12, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        ax1.set_ylim([0, 1.05])
        
        # Plot 2: mAP Scores
        ax2 = axes[1]
        if 'metrics/mAP50(B)' in df.columns:
            ax2.plot(epochs, df['metrics/mAP50(B)'], label='mAP@0.5', 
                    color='#e67e22', linewidth=2, marker='o', markersize=4)
        if 'metrics/mAP50-95(B)' in df.columns:
            ax2.plot(epochs, df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', 
                    color='#1abc9c', linewidth=2, marker='s', markersize=4)
        ax2.set_xlabel('Epoch', fontsize=11)
        ax2.set_ylabel('mAP Score', fontsize=11)
        ax2.set_title('Mean Average Precision', fontsize=12, fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim([0, 1.05])
        
        plt.tight_layout()
        plt.close(fig)
        return fig

    def log_all_training_visualizations(self, trainer):
        """
        Comprehensive logging of all training visualizations to W&B.
        This should be called in the on_train_end callback.
        
        Args:
            trainer: Ultralytics trainer object with access to results
        """
        # Get the save directory where Ultralytics stores results
        save_dir = Path(trainer.save_dir)
        results_csv = save_dir / 'results.csv'
        
        visualizations = {}
        
        # 1. Plot and log training losses
        loss_fig = self.plot_training_losses(results_csv)
        if loss_fig:
            visualizations['training_losses'] = wandb.Image(loss_fig)
        
        # 2. Plot and log metrics
        metrics_fig = self.plot_metrics(results_csv)
        if metrics_fig:
            visualizations['validation_metrics'] = wandb.Image(metrics_fig)
        
        # 3. Log Ultralytics' built-in plots if they exist
        plots_to_log = {
            'confusion_matrix': save_dir / 'confusion_matrix.png',
            'confusion_matrix_normalized': save_dir / 'confusion_matrix_normalized.png',
            'results': save_dir / 'results.png',
            'PR_curve': save_dir / 'PR_curve.png',
            'F1_curve': save_dir / 'F1_curve.png',
            'P_curve': save_dir / 'P_curve.png',
            'R_curve': save_dir / 'R_curve.png',
            'labels': save_dir / 'labels.jpg',
            'labels_correlogram': save_dir / 'labels_correlogram.jpg',
        }
        
        for plot_name, plot_path in plots_to_log.items():
            if plot_path.exists():
                visualizations[f'ultralytics_{plot_name}'] = wandb.Image(str(plot_path))
        
        # 4. Log validation batch predictions if available
        val_batch_path = save_dir / 'val_batch0_pred.jpg'
        if val_batch_path.exists():
            visualizations['validation_predictions'] = wandb.Image(str(val_batch_path))
        
        # Log everything to W&B
        if visualizations:
            wandb.log(visualizations)
            print(f"Logged {len(visualizations)} visualizations to W&B")
        
        return visualizations